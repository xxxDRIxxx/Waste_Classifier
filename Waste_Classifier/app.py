import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
import av
import os

# ============================
# âœ… Paths
# ============================
MODEL_PATH = os.path.join(os.path.dirname(__file__), "my_model 1.pt")
REACT_UI_PATH = "ui/dist/index.html"  # <- after building React

# ============================
# âœ… Page Config
# ============================
st.set_page_config(page_title="Waste Classifier", page_icon="ğŸ—‘ï¸", layout="wide")

# ============================
# âœ… Custom CSS (for iframe & layout)
# ============================
st.markdown("""
    <style>
    .main {
        padding: 0;
        margin: 0;
    }
    iframe {
        width: 100%;
        height: 550px;
        border: none;
        border-radius: 10px;
    }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸš€ Waste Classifier using YOLOv8")

# ============================
# âœ… Load Model
# ============================
@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        st.error(f"âŒ Model file not found at: {MODEL_PATH}")
        st.stop()
    return YOLO(MODEL_PATH)

model = load_model()

# ============================
# âœ… Sidebar Settings
# ============================
st.sidebar.header("âš™ï¸ Settings")
source_option = st.sidebar.radio("Select input source:", ("ğŸ–¼ï¸ React UI", "ğŸ“¸ Webcam", "ğŸ“‚ Upload Image"))
confidence = st.sidebar.slider("Confidence threshold", 0.01, 1.0, 0.25, 0.01)

# ============================
# âœ… React UI Embed
# ============================
if source_option == "ğŸ–¼ï¸ React UI":
    st.markdown(
        f"""
        <iframe src="{REACT_UI_PATH}"></iframe>
        """,
        unsafe_allow_html=True
    )

# ============================
# âœ… YOLO Video Transformer (recv replaces transform)
# ============================
class YOLOVideoTransformer(VideoTransformerBase):
    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        results = model.predict(img, conf=confidence, verbose=False)
        annotated = results[0].plot()
        return av.VideoFrame.from_ndarray(annotated, format="bgr24")

# ============================
# ğŸ“¸ Webcam Mode
# ============================
if source_option == "ğŸ“¸ Webcam":
    st.info("ğŸ“¸ Allow browser webcam access for live YOLO detection")

    RTC_CONFIGURATION = RTCConfiguration({
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    })

    try:
        webrtc_ctx = webrtc_streamer(
            key="yolo-waste",
            video_transformer_factory=YOLOVideoTransformer,
            media_stream_constraints={"video": True, "audio": False},
            rtc_configuration=RTC_CONFIGURATION,
        )
    except Exception as e:
        st.error(f"âš ï¸ Webcam error: {e}")

    if not webrtc_ctx.state.playing:
        st.warning("âš ï¸ Waiting for webcam connection... Check your network or browser permissions.")

# ============================
# ğŸ“‚ Image Upload Mode
# ============================
elif source_option == "ğŸ“‚ Upload Image":
    uploaded_file = st.file_uploader("ğŸ“‚ Upload an image", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        img_np = np.array(image)
        img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        results = model.predict(img_bgr, conf=confidence, verbose=False)
        annotated = results[0].plot()

        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
        st.image(annotated_rgb, caption="ğŸ§  Detected Waste", use_container_width=True)
